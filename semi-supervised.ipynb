{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>aneurysmLocation</th>\n",
       "      <th>aneurysmType</th>\n",
       "      <th>ruptureStatus</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>multipleAneurysms</th>\n",
       "      <th>sacVolume</th>\n",
       "      <th>sacSurfaceArea</th>\n",
       "      <th>...</th>\n",
       "      <th>maxPressure</th>\n",
       "      <th>meanPressure</th>\n",
       "      <th>maxSpeed</th>\n",
       "      <th>meanSpeed</th>\n",
       "      <th>minTAWSS</th>\n",
       "      <th>maxTAWSS</th>\n",
       "      <th>meanTAWSS</th>\n",
       "      <th>minOSI</th>\n",
       "      <th>maxOSI</th>\n",
       "      <th>meanOSI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0001</td>\n",
       "      <td>P0085</td>\n",
       "      <td>ICA</td>\n",
       "      <td>LAT</td>\n",
       "      <td>U</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>125.259604</td>\n",
       "      <td>120.453515</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0002</td>\n",
       "      <td>P0112</td>\n",
       "      <td>ICA</td>\n",
       "      <td>LAT</td>\n",
       "      <td>U</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>119.002032</td>\n",
       "      <td>122.427263</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0003</td>\n",
       "      <td>P0115</td>\n",
       "      <td>ICA</td>\n",
       "      <td>TER</td>\n",
       "      <td>U</td>\n",
       "      <td>43</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>12.740609</td>\n",
       "      <td>23.480617</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C0004</td>\n",
       "      <td>P0116</td>\n",
       "      <td>ICA</td>\n",
       "      <td>TER</td>\n",
       "      <td>U</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "      <td>True</td>\n",
       "      <td>9.376307</td>\n",
       "      <td>18.084625</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0005</td>\n",
       "      <td>P0118</td>\n",
       "      <td>ICA</td>\n",
       "      <td>LAT</td>\n",
       "      <td>R</td>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>37.934454</td>\n",
       "      <td>54.844592</td>\n",
       "      <td>...</td>\n",
       "      <td>7665.0</td>\n",
       "      <td>3722.28</td>\n",
       "      <td>70.275319</td>\n",
       "      <td>13.19376</td>\n",
       "      <td>0.31251</td>\n",
       "      <td>176.44</td>\n",
       "      <td>20.90888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.44672</td>\n",
       "      <td>0.001574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  case_id patient_id aneurysmLocation aneurysmType ruptureStatus  age sex  \\\n",
       "0   C0001      P0085              ICA          LAT             U   53   F   \n",
       "1   C0002      P0112              ICA          LAT             U   35   F   \n",
       "2   C0003      P0115              ICA          TER             U   43   F   \n",
       "3   C0004      P0116              ICA          TER             U   60   F   \n",
       "4   C0005      P0118              ICA          LAT             R   26   F   \n",
       "\n",
       "   multipleAneurysms   sacVolume  sacSurfaceArea  ...  maxPressure  \\\n",
       "0              False  125.259604      120.453515  ...          NaN   \n",
       "1              False  119.002032      122.427263  ...          NaN   \n",
       "2              False   12.740609       23.480617  ...          NaN   \n",
       "3               True    9.376307       18.084625  ...          NaN   \n",
       "4              False   37.934454       54.844592  ...       7665.0   \n",
       "\n",
       "   meanPressure   maxSpeed  meanSpeed  minTAWSS  maxTAWSS  meanTAWSS  minOSI  \\\n",
       "0           NaN        NaN        NaN       NaN       NaN        NaN     NaN   \n",
       "1           NaN        NaN        NaN       NaN       NaN        NaN     NaN   \n",
       "2           NaN        NaN        NaN       NaN       NaN        NaN     NaN   \n",
       "3           NaN        NaN        NaN       NaN       NaN        NaN     NaN   \n",
       "4       3722.28  70.275319   13.19376   0.31251    176.44   20.90888     0.0   \n",
       "\n",
       "    maxOSI   meanOSI  \n",
       "0      NaN       NaN  \n",
       "1      NaN       NaN  \n",
       "2      NaN       NaN  \n",
       "3      NaN       NaN  \n",
       "4  0.44672  0.001574  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"Merged_Aneurysm.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the data has been loaded correctly\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "\n",
    "# Define the list of characteristics to be used\n",
    "characteristics = [\n",
    "    'age', 'sacVolume', 'sacSurfaceArea', 'vdcVolume', 'vdcSurfaceArea', \n",
    "    'sacSectionArea', 'ellipsoidVolume', 'ellipsoidMaxSemiaxis', \n",
    "    'ellipsoidMidSemiaxis', 'ellipsoidMinSemiaxis', 'sacCenterlineLength', \n",
    "    'ostiumSectionArea', 'ostiumSectionPerimeter', 'ostiumMinSize', \n",
    "    'ostiumMaxSize', 'ostiumShapeFactor', 'aspectRatio_star', 'sizeRatio_star', \n",
    "    'vesselDiameter', 'neckVesselAngle', 'sacVesselAngle', 'meanRadius', \n",
    "    'meanCurvature', 'meanTorsion', 'tortuosity', 'minRadius', 'maxRadius', \n",
    "    'maxCurvature', 'maxTorsion', 'bifurcationAngleInPlane', \n",
    "    'bifurcationAngleOutOfPlane', 'aneurysmLocation', 'aneurysmType'\n",
    "]\n",
    "\n",
    "# Subset the data to include only the specified characteristics and the target variable\n",
    "data_subset = data[characteristics + ['ruptureStatus']]\n",
    "\n",
    "# Separate the target variable\n",
    "X = data_subset.drop(columns=['ruptureStatus'])\n",
    "y = data_subset['ruptureStatus']\n",
    "\n",
    "# Handle missing values for numerical and categorical features separately\n",
    "numerical_columns = X.select_dtypes(include=np.number).columns\n",
    "categorical_columns = X.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "# Impute missing values for numerical columns\n",
    "imputer_numerical = SimpleImputer(strategy='mean')\n",
    "X[numerical_columns] = imputer_numerical.fit_transform(X[numerical_columns])\n",
    "\n",
    "\n",
    "# Encode categorical variables\n",
    "if not categorical_columns.empty:\n",
    "    encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "    encoded_categorical = encoder.fit_transform(X[categorical_columns])\n",
    "    encoded_categorical_columns = encoder.get_feature_names_out(categorical_columns)\n",
    "    X = pd.concat([X.drop(columns=categorical_columns).reset_index(drop=True), \n",
    "                   pd.DataFrame(encoded_categorical, columns=encoded_categorical_columns)], axis=1)\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Feature Scaling for X (numerical and encoded categorical)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Data preprocessing complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sacVolume', 'sacSurfaceArea', 'vdcVolume', 'vdcSurfaceArea',\n",
       "       'sacSectionArea', 'ellipsoidVolume', 'ellipsoidMaxSemiaxis',\n",
       "       'ellipsoidMidSemiaxis', 'ellipsoidMinSemiaxis', 'sacCenterlineLength',\n",
       "       'ostiumSectionArea', 'ostiumSectionPerimeter', 'ostiumMinSize',\n",
       "       'ostiumMaxSize', 'ostiumShapeFactor', 'aspectRatio_star',\n",
       "       'sizeRatio_star', 'vesselDiameter', 'neckVesselAngle', 'sacVesselAngle',\n",
       "       'meanRadius', 'meanCurvature', 'meanTorsion', 'tortuosity', 'minRadius',\n",
       "       'maxRadius', 'maxCurvature', 'maxTorsion', 'bifurcationAngleInPlane',\n",
       "       'bifurcationAngleOutOfPlane', 'aneurysmLocation_BAS',\n",
       "       'aneurysmLocation_ICA', 'aneurysmLocation_MCA', 'aneurysmType_TER'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [50, 100, 200]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "                           param_grid=param_grid, scoring='accuracy', cv=3)\n",
    "grid_search.fit(X_scaled, y_encoded)\n",
    "xgb_model = grid_search.best_estimator_\n",
    "xgb_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
      "Mean Cross-Validation Accuracy: 0.738\n",
      "AUC-ROC Score: 0.725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Get the best model from GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions using cross-validation for the best model\n",
    "y_pred_prob_best = cross_val_predict(best_model, X_scaled, y_encoded, cv=3, method='predict_proba')[:, 1]\n",
    "\n",
    "# Calculate AUC-ROC for the best model\n",
    "auc_roc_best = roc_auc_score(y_encoded, y_pred_prob_best)\n",
    "\n",
    "# Print the best model's parameters and its AUC-ROC\n",
    "print(f\"Best Model Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Mean Cross-Validation Accuracy: {grid_search.best_score_:.3f}\")\n",
    "print(f\"AUC-ROC Score: {auc_roc_best:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:48:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP values computation complete!\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "# Initialize SHAP Explainer\n",
    "explainer = shap.Explainer(xgb_model, X_scaled)\n",
    "\n",
    "# Compute SHAP values\n",
    "shap_values = explainer(X_scaled)\n",
    "\n",
    "print(\"SHAP values computation complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n"
     ]
    }
   ],
   "source": [
    "from umap.umap_ import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dimensionality reduction using UMAP with fixed randomness\n",
    "shap_2d = UMAP(n_components=2, n_neighbors=15, min_dist=0, random_state=42).fit_transform(shap_values.values)\n",
    "\n",
    "# Clustering using HDBSCAN\n",
    "hdbscan = HDBSCAN(min_cluster_size=10, min_samples=5, metric='euclidean')\n",
    "cluster_labels = hdbscan.fit_predict(shap_2d)\n",
    "\n",
    "print(\"HDBSCAN Clustering complete!\")\n",
    "\n",
    "# Scatter plot of clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(shap_2d[:, 0], shap_2d[:, 1], c=cluster_labels, cmap='viridis', s=10)\n",
    "plt.colorbar(label=\"Cluster\")\n",
    "plt.title(\"Clusters of SHAP Values (2D UMAP)\")\n",
    "plt.xlabel(\"UMAP Dimension 1\")\n",
    "plt.ylabel(\"UMAP Dimension 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "score = silhouette_score(shap_2d, cluster_labels)\n",
    "print(f\"Silhouette Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cluster_data = pd.DataFrame(shap_values.values, columns=X.columns)\n",
    "cluster_data['Cluster'] = cluster_labels\n",
    "print(cluster_data.groupby('Cluster').mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame for SHAP values\n",
    "shap_df = pd.DataFrame(shap_values.values, columns=X.columns)\n",
    "\n",
    "# Add cluster labels to the SHAP DataFrame\n",
    "shap_df['Cluster'] = cluster_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by clusters and calculate mean SHAP values\n",
    "cluster_means = shap_df.groupby('Cluster').mean()\n",
    "\n",
    "# Display the top SHAP features for each cluster\n",
    "print(cluster_means.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Cluster and rupture status data\n",
    "cluster_df = pd.DataFrame({\n",
    "    'Cluster': cluster_labels,\n",
    "    'RuptureStatus': y_encoded  # Assuming y_encoded corresponds to ruptureStatus\n",
    "})\n",
    "\n",
    "# Calculate rupture proportions by cluster\n",
    "rupture_distribution = cluster_df.groupby('Cluster')['RuptureStatus'].mean()\n",
    "cluster_sizes = cluster_df.groupby('Cluster')['RuptureStatus'].size()\n",
    "\n",
    "# Create a contingency table for statistical testing\n",
    "contingency_table = pd.crosstab(cluster_df['Cluster'], cluster_df['RuptureStatus'])\n",
    "\n",
    "# Perform chi-squared test\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "rupture_distribution, cluster_sizes, p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency, fisher_exact\n",
    "from itertools import combinations\n",
    "\n",
    "# Get unique cluster pairs\n",
    "cluster_pairs = list(combinations(cluster_df['Cluster'].unique(), 2))\n",
    "\n",
    "# Perform pairwise comparisons\n",
    "results = []\n",
    "for c1, c2 in cluster_pairs:\n",
    "    sub_table = pd.crosstab(\n",
    "        cluster_df[cluster_df['Cluster'].isin([c1, c2])]['Cluster'],\n",
    "        cluster_df[cluster_df['Cluster'].isin([c1, c2])]['RuptureStatus']\n",
    "    )\n",
    "    if sub_table.values.min() < 5:  # Use Fisher's Exact Test for small counts\n",
    "        _, p_value = fisher_exact(sub_table)\n",
    "        test_type = \"Fisher\"\n",
    "    else:  # Use Chi-Square for larger counts\n",
    "        _, p_value, _, _ = chi2_contingency(sub_table)\n",
    "        test_type = \"Chi-Square\"\n",
    "    results.append({'Cluster Pair': (c1, c2), 'p-value': p_value, 'Test': test_type})\n",
    "\n",
    "# Adjust for multiple comparisons (Bonferroni correction)\n",
    "bonferroni_alpha = 0.05 / len(results)  # Adjusted significance level\n",
    "\n",
    "# Output results\n",
    "for result in results:\n",
    "    result['Significant'] = result['p-value'] < bonferroni_alpha\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Plot the summary plot\n",
    "shap.summary_plot(shap_values.values, features=X_scaled, feature_names=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(xgb_model, X_scaled, feature_names=X.columns)\n",
    "shap_values = explainer(X_scaled)\n",
    "\n",
    "shap.plots.heatmap(shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean SHAP values by cluster\n",
    "cluster_summary = cluster_data.groupby('Cluster').mean()\n",
    "print(cluster_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster labels to the original dataset\n",
    "original_data = data[characteristics].copy()\n",
    "original_data['Cluster'] = cluster_labels\n",
    "import seaborn as sns\n",
    "original_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping specified non-numeric features and 'age' from numeric columns\n",
    "numeric_features_filtered = original_data.drop(columns=['Cluster', 'aneurysmLocation', 'aneurysmType', 'age'])\n",
    "\n",
    "# Standardizing the numeric features\n",
    "standardized_features_filtered = pd.DataFrame(\n",
    "    scaler.fit_transform(numeric_features_filtered),\n",
    "    columns=numeric_features_filtered.columns\n",
    ")\n",
    "\n",
    "# Adding the cluster labels back to the standardized data\n",
    "standardized_features_filtered['Cluster'] = original_data['Cluster']\n",
    "\n",
    "# Calculating the mean of each feature grouped by cluster\n",
    "cluster_feature_means_filtered = standardized_features_filtered.groupby('Cluster').mean().T\n",
    "\n",
    "# Creating the heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(cluster_feature_means_filtered, cmap='coolwarm', annot=False, cbar=True, linewidths=0.5)\n",
    "plt.title(\"Heatmap of Standardized Features Stratified by Clusters\")\n",
    "plt.xlabel(\"Clusters\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster labels to the original dataset\n",
    "original_data = data[characteristics].copy()\n",
    "original_data['Cluster'] = cluster_labels\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_columns = original_data.select_dtypes(include=np.number)\n",
    "\n",
    "# Calculate mean feature values for each cluster (true values)\n",
    "true_cluster_summary = numeric_columns.groupby(original_data['Cluster']).mean()\n",
    "\n",
    "# Display the mean true values by cluster\n",
    "print(true_cluster_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df['Prediction'] = xgb_model.predict(X_scaled)\n",
    "cluster_accuracy = cluster_df.groupby('Cluster').apply(lambda x: (x['Prediction'] == x['RuptureStatus']).mean())\n",
    "print(cluster_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import seaborn as sns\n",
    "shap.initjs()\n",
    "\n",
    "# Assuming you used StandardScaler for scaling the features\n",
    "original_values = scaler.inverse_transform(X_scaled[:1000])\n",
    "\n",
    "# Generate the force plot using original feature values\n",
    "shap.force_plot(\n",
    "    explainer.expected_value,\n",
    "    shap_values.values[:1000],\n",
    "    original_values,\n",
    "    feature_names=X.columns\n",
    ")\n",
    "\n",
    "# Save the force plot with original feature values\n",
    "shap.save_html('force_plot.html', shap.force_plot(\n",
    "    explainer.expected_value,\n",
    "    shap_values.values[:1000],\n",
    "    original_values,\n",
    "    feature_names=X.columns\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'aneurysmLocation' and 'aneurysmType' from the original data to X\n",
    "X['aneurysmLocation'] = data['aneurysmLocation']\n",
    "X['aneurysmType'] = data['aneurysmType']\n",
    "\n",
    "# Drop 'aneurysmLocation_BAS' and 'aneurysmLocation_ICA' to maintain the same number of features\n",
    "X = X.drop(columns=['aneurysmLocation_BAS', 'aneurysmLocation_ICA'])\n",
    "\n",
    "# Verify the columns have been updated\n",
    "print(X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot('vesselDiameter', shap_values.values, X, interaction_index='aneurysmLocation', feature_names=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot('vesselDiameter', shap_values.values, X, interaction_index='aneurysmType', feature_names=X.columns)\n",
    "\n",
    "\"\"\"\n",
    "(aneurysmType\n",
    " LAT    3.251116\n",
    " TER    1.892105\n",
    " Name: vesselDiameter, dtype: float64,\n",
    " 'TER',\n",
    " 'LAT')\n",
    " The red points in the SHAP dependence plot correspond to the aneurysm type with the lower mean vesselDiameter, which is TER.\n",
    "The blue points correspond to the aneurysm type with the higher mean vesselDiameter, which is LAT.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot('neckVesselAngle', shap_values.values, X, interaction_index='aneurysmType', feature_names=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot('tortuosity', shap_values.values, X, interaction_index='neckVesselAngle', feature_names=X.columns)\n",
    "shap.dependence_plot('meanTorsion', shap_values.values, X, interaction_index='tortuosity', feature_names=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all features in the SHAP summary plot\n",
    "shap.summary_plot(shap_values.values, features=X, feature_names=X.columns, plot_type=\"layered_violin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrules import SkopeRules\n",
    "\n",
    "\n",
    "# Add cluster labels to the original dataset\n",
    "original_data = data[characteristics].copy()\n",
    "original_data['Cluster'] = cluster_labels\n",
    "\n",
    "# Select only numeric columns for rule generation\n",
    "numeric_columns = original_data.select_dtypes(include=np.number).columns\n",
    "numeric_data = original_data[numeric_columns]\n",
    "\n",
    "# Include the cluster labels in the rule generation dataset\n",
    "numeric_data['Cluster'] = cluster_labels\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute missing values for numeric data\n",
    "imputer = SimpleImputer(strategy='mean')  # Use 'mean' to fill missing values\n",
    "numeric_data_imputed = pd.DataFrame(imputer.fit_transform(numeric_data), \n",
    "                                    columns=numeric_data.columns)\n",
    "\n",
    "# Ensure the Cluster column is properly aligned\n",
    "numeric_data_imputed['Cluster'] = cluster_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrules import SkopeRules\n",
    "\n",
    "rules_per_cluster = {}\n",
    "\n",
    "# Loop through each cluster to generate rules\n",
    "for cluster in np.unique(cluster_labels):\n",
    "    print(f\"Generating rules for Cluster {cluster}...\")\n",
    "    \n",
    "    # Create a binary target for the current cluster\n",
    "    numeric_data_imputed['IsCluster'] = (numeric_data_imputed['Cluster'] == cluster).astype(int)\n",
    "    \n",
    "    # Initialize and train SkopeRules\n",
    "    skope = SkopeRules(max_depth=4, n_estimators=30, precision_min=0.5)\n",
    "    skope.fit(numeric_data_imputed.drop(columns=['Cluster', 'IsCluster']), numeric_data_imputed['IsCluster'])\n",
    "    \n",
    "    # Extract and store the rules\n",
    "    rules = skope.rules_\n",
    "    rules_per_cluster[cluster] = rules\n",
    "\n",
    "# Print the rules for each cluster\n",
    "for cluster, rules in rules_per_cluster.items():\n",
    "    print(f\"\\nCluster {cluster} Rules:\")\n",
    "    for rule in rules:\n",
    "        print(rule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Manually define the feature mapping\n",
    "feature_map = {\n",
    "    \"__C__0\": \"age\",\n",
    "    \"__C__1\": \"sacVolume\",\n",
    "    \"__C__2\": \"sacSurfaceArea\",\n",
    "    \"__C__3\": \"vdcVolume\",\n",
    "    \"__C__4\": \"vdcSurfaceArea\",\n",
    "    \"__C__5\": \"sacSectionArea\",\n",
    "    \"__C__6\": \"ellipsoidVolume\",\n",
    "    \"__C__7\": \"ellipsoidMaxSemiaxis\",\n",
    "    \"__C__8\": \"ellipsoidMidSemiaxis\",\n",
    "    \"__C__9\": \"ellipsoidMinSemiaxis\",\n",
    "    \"__C__10\": \"sacCenterlineLength\",\n",
    "    \"__C__11\": \"ostiumSectionArea\",\n",
    "    \"__C__12\": \"ostiumSectionPerimeter\",\n",
    "    \"__C__13\": \"ostiumMinSize\",\n",
    "    \"__C__14\": \"ostiumMaxSize\",\n",
    "    \"__C__15\": \"ostiumShapeFactor\",\n",
    "    \"__C__16\": \"aspectRatio_star\",\n",
    "    \"__C__17\": \"sizeRatio_star\",\n",
    "    \"__C__18\": \"vesselDiameter\",\n",
    "    \"__C__19\": \"neckVesselAngle\",\n",
    "    \"__C__20\": \"sacVesselAngle\",\n",
    "    \"__C__21\": \"meanRadius\",\n",
    "    \"__C__22\": \"meanCurvature\",\n",
    "    \"__C__23\": \"meanTorsion\",\n",
    "    \"__C__24\": \"tortuosity\",\n",
    "    \"__C__25\": \"minRadius\",\n",
    "    \"__C__26\": \"maxRadius\",\n",
    "    \"__C__27\": \"maxCurvature\",\n",
    "    \"__C__28\": \"maxTorsion\",\n",
    "    \"__C__29\": \"bifurcationAngleInPlane\",\n",
    "    \"__C__30\": \"bifurcationAngleOutOfPlane\"\n",
    "}\n",
    "\n",
    "# Function to replace placeholders with feature names using exact matches\n",
    "def replace_placeholders(rule, feature_map):\n",
    "    condition, stats = rule\n",
    "    for placeholder, feature_name in feature_map.items():\n",
    "        # Use regex to replace exact matches of placeholders only\n",
    "        condition = re.sub(rf'\\b{re.escape(placeholder)}\\b', feature_name, condition)\n",
    "    return f\"{condition} (Support: {stats[2]}, Precision: {stats[0]}, Recall: {stats[1]})\"\n",
    "\n",
    "# Replace placeholders for all clusters\n",
    "for cluster, rules in rules_per_cluster.items():\n",
    "    print(f\"\\nCluster {cluster} Mapped Rules:\")\n",
    "    for rule in rules:\n",
    "        print(replace_placeholders(rule, feature_map))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numeric_data_imputed.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster, rules in rules_per_cluster.items():\n",
    "    print(f\"Raw Rules for Cluster {cluster}: {rules}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank rules by precision and support\n",
    "ranked_rules = {}\n",
    "\n",
    "for cluster, rules in rules_per_cluster.items():\n",
    "    ranked_rules[cluster] = sorted(\n",
    "        rules, key=lambda x: (x[1][0], x[1][2]), reverse=True  # Sort by precision, then support\n",
    "    )\n",
    "\n",
    "# Display top-ranked rules for each cluster\n",
    "for cluster, rules in ranked_rules.items():\n",
    "    print(f\"\\nTop Rules for Cluster {cluster}:\")\n",
    "    for rule in rules[:5]:  # Display top 5 rules\n",
    "        print(replace_placeholders(rule, feature_map))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot feature distributions \n",
    "features_to_plot = ['vesselDiameter', 'neckVesselAngle', 'ellipsoidVolume', 'sacSectionArea', 'bifurcationAngleInPlane', 'bifurcationAngleOutOfPlane']\n",
    "for feature in features_to_plot:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(data=original_data, x='Cluster', y=feature)\n",
    "    plt.title(f'{feature} Distribution by Cluster')\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.ylabel(feature)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
